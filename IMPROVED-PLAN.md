# ‚úÖ PHASE 3: Improved Production-Readiness Plan

## üéØ Philosophy Change

**OLD**: Try to fix everything, use manual CLIs, hope for the best
**NEW**: Start small, use official tools, verify each step, expand gradually

---

## üöÄ Revised Implementation Strategy

### Tier 1: Use Official GitHub Actions (SAFE)
Use provider-maintained actions - they handle installation, auth, everything.

### Tier 2: Use API Calls Directly (SAFER)
If actions don't exist, call APIs directly with curl.

### Tier 3: Use CLIs (RISKY)
Only if absolutely necessary, and test extensively first.

---

## üìã Research Phase (DO THIS FIRST!)

### Step 1: Verify What Actually Exists

```bash
# Test these RIGHT NOW before implementing:

# 1. Google Gemini - Official GitHub Action
https://github.com/google-github-actions/run-gemini-cli

# 2. Anthropic Claude - Check if official action exists
https://github.com/anthropics/claude-code-action  # Need to verify

# 3. GitHub Copilot - CLI extension
gh extension list | grep copilot

# 4. Alternative: Direct API calls
curl https://api.anthropic.com/v1/messages  # Anthropic API
curl https://generativelanguage.googleapis.com/v1beta/models  # Gemini API
```

### Step 2: Determine Best Approach Per AI

| AI | Best Method | Fallback | Confidence |
|----|-------------|----------|------------|
| Gemini | ‚úÖ Official Action | API call | HIGH |
| Claude | ‚ùì Check if action exists | API call | MEDIUM |
| Copilot | ‚úÖ gh extension | GitHub Script | HIGH |

---

## üéØ PRAGMATIC IMPLEMENTATION PLAN

### Phase 1: Single Workflow, Single AI, Production-Ready (2 hours)

**Target**: Make `autonomous-improvement.yml` work with Gemini ONLY

**Why This One**:
- Simplest logic (find TODO, implement it)
- Single AI needed
- Low cost (runs weekly, not on every PR)
- Easy to verify (creates visible PR)
- Not critical path (failure doesn't block development)

#### Implementation Steps

```yaml
# 1. Use Official Gemini GitHub Action
- name: ü§ñ Run AI Improvement
  uses: google-github-actions/run-gemini-cli@v1
  with:
    api-key: ${{ secrets.GOOGLE_API_KEY }}
    prompt-file: 'improvement-prompt.txt'
    output-file: 'improvement-output.json'
  continue-on-error: true  # Don't fail workflow if AI unavailable

# 2. Add validation BEFORE using output
- name: ‚úÖ Validate AI Output
  id: validate
  run: |
    if [ ! -f "improvement-output.json" ]; then
      echo "valid=false" >> $GITHUB_OUTPUT
      echo "‚ö†Ô∏è AI output not generated"
      exit 0
    fi

    # Validate JSON structure
    if ! jq empty improvement-output.json 2>/dev/null; then
      echo "valid=false" >> $GITHUB_OUTPUT
      echo "‚ö†Ô∏è Invalid JSON output"
      exit 0
    fi

    # Check for error responses
    if jq -e '.error' improvement-output.json > /dev/null; then
      echo "valid=false" >> $GITHUB_OUTPUT
      echo "‚ö†Ô∏è AI returned error: $(jq -r '.error' improvement-output.json)"
      exit 0
    fi

    echo "valid=true" >> $GITHUB_OUTPUT
    echo "‚úÖ AI output validated"

# 3. Only proceed if valid
- name: üìù Apply Changes
  if: steps.validate.outputs.valid == 'true'
  run: |
    # Apply changes...
```

#### Success Criteria
- [ ] Workflow runs without errors
- [ ] Uses official Gemini action
- [ ] Validates all outputs
- [ ] Creates PR with changes
- [ ] Cost < $0.10 per run
- [ ] Runtime < 5 minutes
- [ ] Works with free tier

---

### Phase 2: Add Proper Error Handling & Monitoring (1 hour)

**Add to Phase 1 workflow**:

```yaml
# Error tracking
- name: üìä Track Workflow Metrics
  if: always()
  run: |
    # Create metrics file
    cat > workflow-metrics.json << METRICS
    {
      "workflow": "autonomous-improvement",
      "run_id": "${{ github.run_id }}",
      "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
      "success": "${{ job.status == 'success' }}",
      "ai_used": "gemini",
      "cost_estimate": "0.001",
      "runtime_seconds": "$SECONDS"
    }
    METRICS

    # In production, send to analytics
    # For now, just save as artifact
    echo "üìä Metrics collected"

- name: üí¨ Post Status Comment (on failure)
  if: failure()
  uses: actions/github-script@v7
  with:
    script: |
      // If this workflow failed, create an issue
      await github.rest.issues.create({
        owner: context.repo.owner,
        repo: context.repo.repo,
        title: '‚ö†Ô∏è Autonomous Improvement Workflow Failed',
        body: `The autonomous improvement workflow failed.

        **Run ID**: ${{ github.run_id }}
        **Time**: ${new Date().toISOString()}
        **Logs**: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}

        Please investigate and fix.`,
        labels: ['ci-cd', 'automated', 'needs-investigation']
      });

# Safety checks
- name: üîí Security Scan Generated Code
  if: steps.validate.outputs.valid == 'true'
  run: |
    # Scan for common issues
    if grep -r "password\|secret\|api.key\|token" changes/ 2>/dev/null; then
      echo "‚ö†Ô∏è Potential secrets detected in generated code!"
      echo "Blocking commit for security review"
      exit 1
    fi

    # Scan for dangerous patterns
    if grep -r "eval(\|exec(\|system(" changes/ 2>/dev/null; then
      echo "‚ö†Ô∏è Dangerous code patterns detected!"
      exit 1
    fi

    echo "‚úÖ Security scan passed"
```

---

### Phase 3: Clone Pattern to Other Workflows (2-3 hours)

**Once Phase 1 + 2 work perfectly**, clone the pattern:

#### Order of Implementation:
1. ‚úÖ `autonomous-improvement.yml` (DONE in Phase 1)
2. `predictive-ci.yml` (similar pattern)
3. `ai-archaeology.yml` (add git handling)
4. `adversarial-testing.yml` (add backend startup)
5. `ai-council-debate.yml` (LAST - most complex)

#### Pattern to Clone:

```yaml
name: Workflow Name

on:
  # appropriate trigger

jobs:
  main:
    runs-on: ubuntu-latest
    steps:
      # 1. Standard setup
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      # 2. Prepare prompt
      - name: üìù Prepare Prompt
        run: |
          cat > prompt.txt << 'EOF'
          [Specific prompt for this workflow]
          EOF

      # 3. Use Official Gemini Action
      - name: ü§ñ Run AI Analysis
        uses: google-github-actions/run-gemini-cli@v1
        with:
          api-key: ${{ secrets.GOOGLE_API_KEY }}
          prompt-file: 'prompt.txt'
          output-file: 'output.json'
        continue-on-error: true

      # 4. Validate Output
      - name: ‚úÖ Validate AI Output
        id: validate
        run: |
          # [Validation logic from Phase 2]

      # 5. Security Scan
      - name: üîí Security Scan
        if: steps.validate.outputs.valid == 'true'
        run: |
          # [Security scan from Phase 2]

      # 6. Apply Changes
      - name: üìù Apply Changes
        if: steps.validate.outputs.valid == 'true'
        run: |
          # [Workflow-specific logic]

      # 7. Track Metrics
      - name: üìä Track Metrics
        if: always()
        run: |
          # [Metrics from Phase 2]

      # 8. Error Handling
      - name: üí¨ Handle Failure
        if: failure()
        # [Error handling from Phase 2]
```

---

### Phase 4: Add Multi-AI Support to AI Council (1-2 hours)

**Only after all others work**, enhance AI Council:

```yaml
# Run three analyses in parallel
parallel-reviews:
  strategy:
    matrix:
      ai: [gemini, copilot]  # Start with 2, add Claude later
  steps:
    - name: Review with ${{ matrix.ai }}
      # Use appropriate action for each

# Synthesize results
synthesize:
  needs: parallel-reviews
  steps:
    - name: Combine Reviews
      # Merge all reviews

# Detect which AIs are available
check-availability:
  outputs:
    has_gemini: ${{ secrets.GOOGLE_API_KEY != '' }}
    has_claude: ${{ secrets.CLAUDE_CODE_API_KEY != '' }}
    has_copilot: true  # Always available
```

---

## üîß Fallback Strategy

### If Official Actions Don't Exist

Use direct API calls:

```yaml
# Gemini API (if action doesn't work)
- name: ü§ñ Call Gemini API Directly
  run: |
    curl -X POST \
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${{ secrets.GOOGLE_API_KEY }}" \
      -H 'Content-Type: application/json' \
      -d '{
        "contents": [{
          "parts": [{
            "text": "'"$(cat prompt.txt)"'"
          }]
        }]
      }' \
      -o response.json

    # Extract text from response
    jq -r '.candidates[0].content.parts[0].text' response.json > output.txt

# Claude API (if action doesn't exist)
- name: ü§ñ Call Claude API Directly
  run: |
    curl -X POST \
      "https://api.anthropic.com/v1/messages" \
      -H "x-api-key: ${{ secrets.ANTHROPIC_API_KEY }}" \
      -H "anthropic-version: 2023-06-01" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "claude-3-5-sonnet-20241022",
        "max_tokens": 4096,
        "messages": [{
          "role": "user",
          "content": "'"$(cat prompt.txt)"'"
        }]
      }' \
      -o response.json

    # Extract text
    jq -r '.content[0].text' response.json > output.txt
```

**Advantage**: API calls are more reliable than CLI installation!

---

## üí∞ Cost Management

### Add to EVERY Workflow

```yaml
# Before running AI
- name: üí∞ Check Cost Budget
  id: cost-check
  run: |
    # Load monthly usage (from artifact or API)
    USAGE_THIS_MONTH=$(cat .ai-usage/current-month.txt 2>/dev/null || echo "0")

    # Set monthly budget (in cents)
    MONTHLY_BUDGET=1000  # $10/month

    if [ "$USAGE_THIS_MONTH" -gt "$MONTHLY_BUDGET" ]; then
      echo "‚ö†Ô∏è Monthly AI budget exceeded ($USAGE_THIS_MONTH cents / $MONTHLY_BUDGET cents)"
      echo "should_run=false" >> $GITHUB_OUTPUT
      exit 0
    fi

    echo "should_run=true" >> $GITHUB_OUTPUT

# Only run if budget allows
- name: ü§ñ Run AI (if budget allows)
  if: steps.cost-check.outputs.should_run == 'true'
  # ...AI operation...

# Track usage
- name: üìä Update Usage Tracking
  if: always()
  run: |
    # Estimate cost (this run)
    COST_CENTS=5  # Estimate $0.05 per run

    # Update monthly total
    mkdir -p .ai-usage
    CURRENT=$(cat .ai-usage/current-month.txt 2>/dev/null || echo "0")
    NEW_TOTAL=$((CURRENT + COST_CENTS))
    echo "$NEW_TOTAL" > .ai-usage/current-month.txt

    echo "üí∞ Updated usage: $NEW_TOTAL cents this month"
```

---

## üìù Documentation Updates

### Create New File: `WORKFLOWS.md`

```markdown
# AI-Powered Workflows - Production Guide

## Active Workflows

### 1. Autonomous Code Improvement
**File**: `.github/workflows/autonomous-improvement.yml`
**Status**: ‚úÖ Production Ready
**AI**: Gemini (free tier)
**Trigger**: Weekly (Monday 2 AM) or manual
**Cost**: ~$0.05/run, ~$0.20/month
**Description**: Automatically implements TODOs

### 2. [Others as they're implemented]

## Setup Required

1. Add Gemini API key (FREE):
   ```bash
   gh secret set GOOGLE_API_KEY --body "your-key"
   ```

2. That's it! Workflow runs automatically.

## Monitoring

Check workflow status:
```bash
gh run list --workflow=autonomous-improvement.yml
```

## Cost Tracking

Monthly budget: $10
Current usage: [Check .ai-usage/current-month.txt]

## Troubleshooting

[Add real issues as they're found]
```

---

## ‚úÖ Revised Definition of Done

For EACH workflow (do one at a time):

- [ ] Uses official GitHub Action OR direct API call
- [ ] API key validated before use
- [ ] All outputs validated (JSON, structure, errors)
- [ ] Security scan on generated code
- [ ] Cost tracking implemented
- [ ] Error handling with clear messages
- [ ] Monitoring/metrics collected
- [ ] Tested in real GitHub Actions (not locally)
- [ ] Documentation updated with actual behavior
- [ ] Monthly cost < $2 per workflow

---

## üö¶ Go/No-Go Decision

**Proceed to implementation IF**:
- ‚úÖ Gemini official action exists and works
- ‚úÖ Free tier sufficient for testing
- ‚úÖ Can create test repository for trials
- ‚úÖ Have 4-6 hours for implementation

**DON'T proceed IF**:
- ‚ùå No official actions exist (need to research APIs first)
- ‚ùå Can't test in isolated environment
- ‚ùå Time pressure to ship (do it right or not at all)

---

## üìä Implementation Timeline (Revised)

### Day 1 (2 hours):
- Research: Verify Gemini action exists
- Implement: Phase 1 (autonomous-improvement, Gemini only)
- Test: Run in test repository
- Document: Actual behavior

### Day 2 (2 hours):
- Enhance: Add Phase 2 (error handling, monitoring)
- Test: Verify metrics work
- Refine: Fix issues found

### Day 3 (2 hours):
- Clone: Apply pattern to predictive-ci
- Test: Verify it works
- Compare: Both workflows use same pattern

### Day 4 (2 hours):
- Clone: Apply to ai-archaeology
- Clone: Apply to adversarial-testing
- Test: All work individually

### Day 5 (2 hours):
- Multi-AI: Add to ai-council
- Test: Verify with 2 AIs
- Document: Complete workflows guide

**Total: 10 hours over 5 days** (safe, methodical)

---

## üéØ Success Metrics

After implementation:
- ‚úÖ At least 1 workflow runs successfully in production
- ‚úÖ Monthly cost < $10
- ‚úÖ No security issues
- ‚úÖ Clear error messages when things fail
- ‚úÖ Documentation matches reality
- ‚úÖ Team understands how to use it

---

_Improved Plan created: 2025-11-05_
_Based on: Critique findings + Pragmatic approach_
_Ready for: Executive decision and implementation_
